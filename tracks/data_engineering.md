# Trilha T√©cnica ‚Äì Data Engineering

> Esta trilha foca exclusivamente em **habilidades t√©cnicas (Craft)** para Data Engineers. Para compet√™ncias comportamentais (Results, Direction, Talent, Culture), consulte os arquivos em [`/levels/`](../levels/).

---

## Vis√£o Geral

**Data Engineers** s√£o respons√°veis por construir e manter pipelines, modelos de dados e arquiteturas que tornem dados confi√°veis, acess√≠veis e √∫teis para produtos, an√°lises e modelos de IA.

### Tech Stack & Tools
- **Data Warehouse**: BigQuery, Snowflake
- **Ingestion & Integration**: Fivetran, Airbyte, APIs
- **Orchestration**: Apache Airflow, Dagster
- **Transformation**: dbt (data build tool)
- **Languages**: SQL (avan√ßado), Python
- **Infrastructure**: Docker, Kubernetes, Terraform
- **CI/CD**: GitHub Actions, GitLab CI
- **Observability**: Datadog, Monte Carlo, dbt Cloud

---

## SE I ‚Äì Junior Data Engineer

üîó **Compet√™ncias comportamentais**: [`SE_I_junior.md`](../levels/SE_I_junior.md)

### Entregas Principais
- Implementa componentes individuais de produtos de dados sob orienta√ß√£o
- Escreve queries SQL simples a m√©dias e scripts Python b√°sicos
- Contribui em partes de pipelines de dados existentes

### SQL & Queries
- Proficiente em SELECT, JOIN, GROUP BY, HAVING, subqueries
- Entende diferen√ßa entre INNER/LEFT/RIGHT/FULL OUTER JOIN
- Usa CTEs (Common Table Expressions) para organizar queries
- Aplica fun√ß√µes de agrega√ß√£o (SUM, COUNT, AVG, MIN, MAX)
- Entende conceitos b√°sicos de window functions

### Python
- Escreve scripts para manipula√ß√£o de dados (pandas b√°sico)
- Usa bibliotecas como requests para APIs
- Entende list comprehensions, dictionaries, functions
- Segue PEP 8 (guia de estilo Python)

### dbt (data build tool)
- Entende estrutura de projeto dbt (models, tests, docs)
- Escreve models simples (.sql files)
- Adiciona testes de esquema (not_null, unique)
- Documenta models com descriptions

### Pipelines & Orchestration
- Entende conceito de DAGs (Directed Acyclic Graphs)
- Executa e monitora DAGs existentes no Airflow
- Identifica falhas b√°sicas e reporta

### Qualidade de Dados
- Escreve testes de esquema b√°sicos no dbt
- Valida outputs comparando com especifica√ß√µes
- Documenta processos e assumptions

### Boas Pr√°ticas
- Segue guias de estilo e conven√ß√µes do time
- Comenta c√≥digo adequadamente
- Mant√©m trilha de auditoria (trabalho replic√°vel)
- Usa versionamento (git) efetivamente

---

## SE II ‚Äì Pleno Data Engineer

üîó **Compet√™ncias comportamentais**: [`SE_II_pleno.md`](../levels/SE_II_pleno.md)

### Entregas Principais (SE I+)
- Implementa componentes completos de forma independente
- Desenvolve pipelines end-to-end com testes
- Automatiza processos repetitivos

### SQL & Queries (SE I+)
- **Fluente** em SQL: escreve queries complexas com m√∫ltiplos CTEs
- Domina window functions (ROW_NUMBER, RANK, LAG, LEAD)
- Usa QUALIFY, PIVOT/UNPIVOT quando apropriado
- Otimiza queries para performance (analisa query plans)
- Entende particionamento e clustering

### Python (SE I+)
- Proficiente em pandas para ETL
- Escreve c√≥digo modular e test√°vel (functions, classes)
- Usa type hints e docstrings
- Trabalha com APIs (requests, autentica√ß√£o)
- Entende async/await para opera√ß√µes I/O

### dbt (SE I+)
- Cria models complexos com macros e Jinja
- Implementa testes de dados customizados
- Usa pacotes dbt (dbt_utils, dbt_expectations)
- Configura materializations (table, view, incremental)
- Documenta com docs blocks e schema.yml

### Pipelines & Orchestration (SE I+)
- Cria DAGs no Airflow com operators apropriados
- Implementa retries, timeouts e alertas
- Usa XComs para passar dados entre tasks
- Entende dependency management

### Modelagem de Dados
- Aplica normaliza√ß√£o vs denormaliza√ß√£o
- Cria fact e dimension tables (Kimball b√°sico)
- Entende slowly changing dimensions (SCD Type 1, 2)
- Modela dados para analytics (star schema)

### Qualidade de Dados (SE I+)
- Implementa testes de integridade (referential integrity)
- Cria alertas proativos para anomalias
- Monitora freshness de dados
- Documenta data quality checks

### Performance & Otimiza√ß√£o
- Otimiza queries analisando execution plans
- Usa particionamento e clustering efetivamente
- Entende custos de queries no BigQuery
- Implementa caching quando apropriado

---

## SE III ‚Äì Senior Data Engineer

üîó **Compet√™ncias comportamentais**: [`SE_III_senior.md`](../levels/SE_III_senior.md)

### Entregas Principais (SE II+)
- Desenha e implementa sistemas de dados completos
- Define arquitetura de pipelines e modelos
- Lidera tecnicamente projetos de dados complexos

### SQL & Queries (SE II+)
- **Expert** em SQL: otimiza√ß√£o avan√ßada, window functions complexas
- Resolve problemas de performance de queries
- Usa SQL procedural (stored procedures, user-defined functions)
- Entende profundamente query execution e planos

### Python (SE II+)
- Escreve c√≥digo production-ready com testes abrangentes
- Usa design patterns apropriados
- Implementa logging e monitoring
- Trabalha com frameworks (FastAPI, Flask para APIs)
- Otimiza c√≥digo para performance (profiling)

### dbt (SE II+)
- Arquiteta estrutura de projetos dbt complexos
- Cria macros reutiliz√°veis e packages internos
- Implementa estrat√©gias avan√ßadas de incremental models
- Otimiza builds dbt para performance
- Define padr√µes de modelagem para o time

### Modelagem de Dados Avan√ßada
- **Kimball**: fact tables, dimension tables, conformed dimensions
- **Data Vault**: hubs, links, satellites
- **Abordagens orientadas a dom√≠nio**: bounded contexts
- Escolhe abordagem apropriada para caso de uso
- Desenha data contracts entre servi√ßos

### Pipelines & Orchestration (SE II+)
- Arquiteta pipelines complexos com m√∫ltiplas depend√™ncias
- Implementa patterns de resili√™ncia (idempot√™ncia, retries exponenciais)
- Otimiza paraleliza√ß√£o de tasks
- Implementa monitoring e alerting robusto
- Usa sensors e hooks avan√ßados no Airflow

### Qualidade & Observabilidade
- Implementa framework de testes de dados comprehensivo
  - Testes de esquema (schema)
  - Testes de qualidade (nulls, ranges, distributions)
  - Testes de consist√™ncia (cross-checks)
- Configura **data lineage** (OpenLineage, Monte Carlo)
- Implementa **data observability** (freshness, volume, schema)
- Define SLOs para pipelines cr√≠ticos
- Cria dashboards de monitoring de pipelines

### Infrastructure as Code
- Usa Terraform para provisionar recursos (BigQuery datasets, tables, views)
- Implementa CI/CD para pipelines de dados
- Configura ambientes (dev, staging, prod)
- Automatiza deployments via GitHub Actions

### Performance & Otimiza√ß√£o (SE II+)
- Otimiza **custo** de queries e storage
- Implementa estrat√©gias de particionamento e clustering avan√ßadas
- Usa materialized views quando apropriado
- Profila pipelines para identificar bottlenecks
- Implementa caching strategies (Redis, Memcached)

### Seguran√ßa & Governan√ßa
- Implementa column-level security
- Configura roles e permissions (least privilege)
- Garante compliance (LGPD, GDPR)
- Implementa data masking para dados sens√≠veis
- Documenta data catalog e metadata

---

## Lead Engineer

üîó **Compet√™ncias comportamentais**: [`Lead_engineer.md`](../levels/Lead_engineer.md)

### Entregas Principais (SE III+)
- Define arquitetura de dados de longo prazo para a √°rea
- Resolve problemas t√©cnicos mais complexos da organiza√ß√£o
- Cria frameworks e patterns reutiliz√°veis

### Arquitetura de Dados
- Desenha **arquitetura de dados** escal√°vel para m√∫ltiplos dom√≠nios
- Define **data mesh** vs **data lake** vs **data warehouse** strategies
- Implementa **data lakehouse** patterns (Delta Lake, Iceberg)
- Arquiteta para **multi-tenancy** e **isolation**
- Define estrat√©gias de **data retention** e **archiving**

### Plataforma de Dados
- Desenha abstra√ß√µes e interfaces que permitem self-service
- Cria frameworks internos (ex: dbt packages, Airflow operators customizados)
- Implementa **data platform APIs**
- Define **data contracts** e governance
- Estabelece **data quality framework** organizacional

### Performance em Escala
- Otimiza para **escala** (TB ‚Üí PB de dados)
- Implementa **streaming** (Kafka, Pub/Sub) quando apropriado
- Desenha para **real-time** vs **batch** appropriadamente
- Otimiza custos em escala (query optimization, storage tiering)

### Expertise Profunda
- Expert em pelo menos um dom√≠nio (ex: streaming, ML pipelines, data lakehouse)
- Refer√™ncia t√©cnica para Data Engineers do time
- Contribui para comunidade (blog posts, talks, open source)

---

## Staff Engineer

üîó **Compet√™ncias comportamentais**: [`Staff_engineer.md`](../levels/Staff_engineer.md)

### Entregas Principais (Lead+)
- Define estrat√©gia t√©cnica de dados multi-ano
- Influencia arquitetura de dados de m√∫ltiplos times
- Cria capacidades t√©cnicas que impactam toda organiza√ß√£o

### Estrat√©gia de Dados
- Define **vis√£o de plataforma de dados** de 2-3 anos
- Avalia e promove ado√ß√£o de novas tecnologias (ex: dbt Cloud, Fivetran vs custom)
- Define estrat√©gia de **build vs buy** para componentes de plataforma
- Alinha estrat√©gia t√©cnica com objetivos de neg√≥cio

### Arquitetura Organizacional
- Desenha **data architecture** que serve m√∫ltiplos times
- Define **standards e best practices** organizacionais
- Cria **governance model** escal√°vel
- Implementa **federated data platform** (data mesh principles)

### Lideran√ßa T√©cnica
- Eleva capacidade t√©cnica de m√∫ltiplos times
- Mentora Lead e Senior Engineers
- Conduz **RFCs** (Request for Comments) t√©cnicos significativos
- Representa Data Engineering em decis√µes arquiteturais company-wide

---

## Staff II & Principal Engineer

üîó **Compet√™ncias comportamentais**: 
- [`Staff_II_senior_staff.md`](../levels/Staff_II_senior_staff.md)
- [`Principal_engineer.md`](../levels/Principal_engineer.md)

### Entregas Principais
- Define dire√ß√£o t√©cnica de dados para a empresa inteira
- Resolve os desafios t√©cnicos mais complexos e estrat√©gicos
- Influencia ind√∫stria atrav√©s de lideran√ßa de pensamento

### Estrat√©gia Company-Wide
- Define arquitetura de dados de 3-5 anos alinhada com estrat√©gia de neg√≥cio
- Avalia e influencia decis√µes de M&A do ponto de vista de dados
- Define **data strategy** que cria vantagem competitiva

### Technical Vision
- Articula vis√£o t√©cnica que inspira organiza√ß√£o
- Identifica tend√™ncias tecnol√≥gicas e posiciona empresa
- Cria frameworks que transformam capacidades da empresa

### Industry Leadership
- Publica pesquisa, contribui para open source significativo
- Palestras em confer√™ncias principais
- Representa empresa como l√≠der de pensamento em dados

---

## üìö Recursos de Aprendizado

### Fundamentos
- [SQL for Data Scientists](https://mode.com/sql-tutorial/)
- [Python for Data Engineering](https://realpython.com/)
- [dbt Learn](https://courses.getdbt.com/)

### Avan√ßado
- [Data Engineering Zoomcamp (DataTalks.Club)](https://github.com/DataTalksClub/data-engineering-zoomcamp)
- [The Data Engineering Cookbook](https://github.com/andkret/Cookbook)
- [Fundamentals of Data Engineering (O'Reilly Book)](https://www.oreilly.com/library/view/fundamentals-of-data/9781098108298/)

### Certifica√ß√µes Relevantes
- **Google Cloud**: Professional Data Engineer
- **dbt**: Analytics Engineer Certification
- **Airflow**: Astronomer Certification

---

## üîÑ Como Usar Esta Trilha

1. **Identifique seu n√≠vel atual** nos arquivos de `/levels/`
2. **Compare** suas habilidades t√©cnicas com as expectativas desta trilha
3. **Identifique gaps** t√©cnicos espec√≠ficos
4. **Crie plano de desenvolvimento** focado nas skills t√©cnicas que faltam
5. **Pratique** atrav√©s de projetos reais no time
6. **Busque mentoria** de engineers mais seniores em √°reas espec√≠ficas

**Lembre-se**: Craft t√©cnico √© importante, mas n√£o √© suficiente para promo√ß√£o. Voc√™ tamb√©m precisa demonstrar crescimento nas 4 dimens√µes: Results, Direction, Talent e Culture.
